---
layout: post
title: ARKit的能力
category: AR
tags: centos,ftp,Apache,GPL,LGPL,MIT
description: 
---

```javascript
通过设备摄像头为实时视图增添 2D 或 3D 元素，让这些元素看似存在于真实世界中一般，这就是“增强现实 (AR)”所指的用户体验。ARKit 结合运用设备运动跟踪、摄像头场景捕捉、高级场景处理和显示便捷性，简化了打造 AR 体验的工作。你可以使用这些技术，通过 iOS 设备的前置或后置摄像头打造各种不同的增强现实体验。


4K 视频
ARKit 6 中加入了一个选项，可在 ARKit 会话期间使用后置摄像头拍摄 4K 视频。对于将虚拟和现实内容加以融合来创作视频的 App，如社交媒体、专业视频剪辑和电影制作 App 等，4K 视频是理想选择。

Depth API
激光雷达扫描仪中内置了先进的场景理解功能，以助此 API 使用关于周围环境的逐像素深度信息。通过将这种深度信息与由场景几何结构感测生成的 3D 网格数据相结合，你能在 App 中即时放置虚拟物体，并将它们无缝地融入到现实环境中，让虚拟物体的遮挡显得更加真实。这将有助于你在 App 中推出相关新功能，比如进行更精确的测量，或对用户的环境应用某些效果。

即时 AR
激光雷达扫描仪能够实现超快的平面检测 — 无需扫描，便可在现实世界中即时放置 AR 物品。在 iPhone 12 Pro、iPhone 12 Pro Max 和 iPad Pro 上，你无需更改任何代码，所有使用 ARKit 构建的 App 会自动支持即时 AR 物品放置功能。

场景几何结构感测
借助此功能，你可为你的空间创建拓扑图，并使用标签来标识地板、墙壁、天花板、窗户、门和座椅。这种对现实世界的深度理解能帮助你为虚拟对象实现物体遮挡的功能和现实世界的物理特效，同时为你提供更多的信息来支持 AR 工作流程。

人物遮挡
AR 内容能够以逼真的方式从现实世界中的人物前后通过，带来更身临其境的 AR 体验，同时能在几乎任何环境中实现绿屏风格效果。

动作捕捉
用单个摄像头实时捕捉人物的动作。将身体姿态和动作化为一系列关节及骨骼活动，让你能在 AR 体验中输入运动和姿势，让人物成为 AR 体验的焦点。

同时使用前置和后置摄像头
同时使用前置和后置摄像头来进行面部和现实场景追踪，开创更多新的可能。例如，用户可以仅使用自己的面部与后置摄像头视图中的 AR 内容进行交互。

现实场景跟踪
通过跟踪表面、图像、物体、人物或用户面孔，打造后置摄像头增强现实体验。

地理跟踪
跟踪关注的特定地理区域并在增强现实体验中对这些区域进行渲染。

面部跟踪
检测前置摄像头增强现实体验中的面孔，叠加匹配的虚拟内容，并实时生成面部表情动画。

人物
对 ARKit 在相机视频流中检测到的人物做出响应。

图像跟踪
识别物理环境中的图像，并跟踪它们的位置和方向。

物体检测
通过先使用 App 扫描，在运行时识别已知的对象。在增强现实会话期间从物理环境中查找的现实物体。

方向跟踪
只希望用设备后置摄像头跟踪设备方向时使用的配置。

多用户
与其他设备通信，打造共享的 AR 体验。

音频
借助声音效果和环境声音层次，打造富有吸引力的 AR 体验。


文本
利用在屏幕上给现实和虚拟物体贴上虚拟便签，为 AR 体验添加注释。







```



---
